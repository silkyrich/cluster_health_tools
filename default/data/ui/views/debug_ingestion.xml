<form>
  <label>Debug Ingestion</label>
  <description>Another groovy debug dashboard from Richard Morgan</description>
  <init>
    <set token="splunkd">(index=_internal OR index=core_splunk_internal) sourcetype=splunkd source=*splunkd.log*</set>
    <set token="metrics">(index=_internal OR index=core_splunk_internal) (sourcetype=metrics OR sourcetype=splunkd) source=*metrics.log*</set>
    <set token="introspection">index=_introspection</set>
    <set token="series_thruput_max">0</set>
    <eval token="series_thruput_min">now()</eval>
  </init>
  <search id="per_regex_series_thruput">
    <query>
      $metrics$ TERM(group=per_host_regex_cpu) OR TERM(group=per_source_regex_cpu) OR TERM(group=per_sourcetype_regex_cpu) OR TERM(group=per_index_regex_cpu) host=$selected_host$
| fillnull ingest_pipe 0
| table _time host group ingest_pipe series cpu cpupe ev bytes bytes ev 
    </query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
    <progress>
      <eval token="show_regex_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
    </progress>
    <done>
      <eval token="show_regex_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
    </done>
  </search>
  <search id="connecting_forwarders">
    <query>$metrics$ TERM(group=tcpin_connections) host=$selected_host$ earliest=$selection_per_series_earliest$ latest=$selection_per_series_latest$
| fillnull ingest_pipe 0
| eventstats dc(_time) as readings 
| stats 
    sum(kb) as sum_kb
    avg(chan_new_kBps) as avg_chan_new_kBps
    max(tcp_KBps) as max_tcp_KBps
    stdev(tcp_KBps) as stdev_tcp_KBps
    values(connectionType) as connectionType
    values(arch) as arch
    values(version) as version
    values(fwdType) as type
    values(ssl) as ssl
    values(os) as os
    values(guid) as guid
    dc(guid) as guid_count
    dc(sourceIp) as count_sources
    dc(_time) as mentions
    by hostname sourceHost sourcePort ingest_pipe readings
| eventstats 
    sum(max_tcp_KBps) as total_sum_avg_KBps
    stdev(tcp_KBps) as avg_stdev_KBps
    sum(sum_kb) as total_sum_kb 
    dc(guid) as all_forwarders 
    max(indexer_count) as all_indexers
    by ingest_pipe
| eval indexer_coverage=indexer_count."/".all_indexers,
indexer_coverage_pct=indexer_count/all_indexers
| sort 0 - sum_kb 
| streamstats 
    sum(sum_kb) as accumlated_sum_kb 
    count as ranking_most_data_kb
    by all_forwarders ingest_pipe
| eval coverage_kb=accumlated_sum_kb/total_sum_kb, 
    progress_through_forwarders_kb=(ranking_most_data_kb/all_forwarders) * 100 
| sort 0 - max_tcp_KBps 
| streamstats 
    sum(max_tcp_KBps) as accumlated_avg_kbps 
    count as ranking_most_data_kbps
    by all_forwarders ingest_pipe
| eval coverage_kbps=accumlated_avg_kbps/total_sum_avg_KBps, 
    progress_through_forwarders_kbps=(ranking_most_data_kbps/all_forwarders) * 100 
| rename ranking_most_data_kbps as "speed ranking" 
| rename ranking_most_data_kb as "volume ranking" 
| rename max_tcp_KBps as "max speed" 
| eval "%"='%'*100,
    "speed variability" = (stdev_tcp_KBps/'max speed')*100,
    "data"=sum_kb/1024/1024,
    "data %"= (sum_kb/total_sum_kb) * 100
$finished_per_series_thruput$   
    </query>
    <earliest>$selection_thruput_earliest$</earliest>
    <latest>$selection_thruput_latest$</latest>
  </search>
  <search id="per_series_thruput">
    <query>$metrics$ host=$selected_host$ TERM(kb=*) TERM(kbps=*) TERM(ev=*) TERM(eps=*) TERM(group=*) TERM(series=*)
| fillnull ingest_pipe 0
| table _time host group ingest_pipe series eps ev kbps kb max_age avg_age</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="pipeline_processor">
    <query>$metrics$ host=$selected_host$ TERM(group=pipeline) TERM(processor=*)
| fillnull ingest_pipe 0
| table _time host ingest_pipe processor name executes cpu_seconds cumulative_hits
| bin _time $span_min_30s$ 
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search base="pipeline_processor" id="pipeline_processor_aggregated">
    <query>| stats avg(cpu_seconds) as cpu_seconds
    avg(executes) as executes
    avg(cumulative_hits) as cumulative_hits
    by _time processor ingest_pipe name</query>
  </search>
  <search id="annotation_blocking_filtered" base="annotation_blocking">
    <query>
      | search ingest_pipe=$filter_pipelines$
    </query>
  </search>
  <search id="channels">
    <query>
$metrics$ host=$selected_host$ TERM(group=map) TERM(name=pipelineinputchannel)
| fillnull ingest_pipe 0 
| table _time host ingest_pipe current_size inactive_channels new_channels removed_channels reclaimed_channel timedout_channels abandoned_channels 
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="tcp_out">
    <query>$metrics$ TERM(group=tcpout_connections) host=$selected_host$ 
| fillnull ingest_pipe 0 
| bin _time $span_min_30s$ 
| stats
    sum(tcp_Kprocessed) as tcp_Kprocessed
    median(tcp_avg_thruput) as tcp_avg_thruput
    sum(kb) as kb
    avg(tcp_eps) as tcp_eps
    by _time ingest_pipe name sourcePort destIp destPort
| table _time ingest_pipe name sourcePort destIp destPort tcp_Kprocessed tcp_avg_thruput tcp_eps kb
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="annotation_broken_pipes">
    <query>$splunkd$ host=$selected_host$ TcpInputProc Error encountered for connection Broken pipe from TERM(src=*) sourcetype=splunkd
| eval annotation_label=src,
    annotation_category="Dropped forwarder" 
| table _time ann*</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="annotation_parsing_problems">
    <query>$splunkd$ WARN component=DateParserVerbose host=$selected_host$
| eval reason = case(searchmatch("Accepted time format has changed possibly indicating a problem in extracting timestamps"),"Accepted time format has changed possibly indicating a problem in extracting timestamps",
    searchmatch("The TIME_FORMAT specified is matching timestamps outside of the acceptable time window"),"The TIME_FORMAT specified is matching timestamps outside of the acceptable time window",
    searchmatch("A possible timestamp match is outside of the acceptable time window"),"A possible timestamp match is outside of the acceptable time window",
    searchmatch("Failed to parse timestamp. Defaulting to timestamp of previous event"),"Failed to parse timestamp. Defaulting to timestamp of previous event",
    searchmatch("Time parsed is too far away from the previous time"), "Time parsed is too far away from the previous time",
    searchmatch("Accepted time is suspiciously far away from the previous time but still accepted because it was extracted by the same pattern"), "Accepted time is suspiciously far away from the previous time but still accepted because it was extracted by the same pattern",
    searchmatch("Failed to parse timestamp in first MAX_TIMESTAMP_LOOKAHEAD"), "Failed to parse timestamp in first MAX_TIMESTAMP_LOOKAHEAD",
    searchmatch("The TIME_FORMAT specified is matching timestamps outside of the acceptable time window"),"The TIME_FORMAT specified is matching timestamps outside of the acceptable time window",
    searchmatch("The same timestamp has been used for consecutive times. If more than 200K events have the same timestamp, not all events may be retrieveable"), "The same timestamp has been used for consecutive times. If more than 200K events have the same timestamp, not all events may be retrieveable") 
| rex field=_raw "Context:\s+source(::|=)(?&lt;naughty_source&gt;[^\|]+)\|host(::|=)(?&lt;naughty_host&gt;[^\|]+)\|(?&lt;naughty_sourcetype&gt;[^\|]+)\|(?&lt;naughty_number&gt;\d+)?" 
| table _time reason naughty* 
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="per_series_thruput_filtered" base="per_series_thruput">
    <done>
      <set token="finished_per_series_thruput">| noop</set>
    </done>
    <query>| search group=per_$selected_group$_thruput ingest_pipe=$filter_pipelines$ 
| bin _time $span_min_30s$ 
| stats $selected_per_series_function$(eps) as eps
    $selected_per_series_function$(kb) as kb
    $selected_per_series_function$(ev) as ev
    $selected_per_series_function$(kbps) as kbps
    $selected_per_series_function$(max_age) as max_age
    $selected_per_series_function$(avg_age) as avg_age
    by _time series host</query>
  </search>
  <search id="channels_filtered" base="channels">
    <query>
| search ingest_pipe=$filter_pipelines$         
| timechart $span_min_30s$ limit=30
    $selected_channels_function$(current_size) as current_size
    $selected_channels_function$(inactive_channels) as inactive_channels
    $selected_channels_function$(new_channels) as new_channels
    $selected_channels_function$(removed_channels) as removed_channels
    $selected_channels_function$(reclaimed_channel) as reclaimed_channel
    $selected_channels_function$(timedout_channels) as timedout_channels
    $selected_channels_function$(abandoned_channels) as abandoned_channels
    by ingest_pipe
</query>
  </search>
  <search id="hec_token_base">
    <query>
            | tstats 
    avg(data.num_of_events) as num_of_events
    avg(data.num_of_parser_errors) as num_of_parser_errors
    avg(data.num_of_requests) as num_of_requests
    avg(data.num_of_requests_in_mint_format) as num_of_requests_in_mint_format
    avg(data.num_of_requests_to_disabled_token) as num_of_requests_to_disabled_token
    avg(data.total_bytes_indexed) as total_bytes_indexed
    avg(data.total_bytes_received) as total_bytes_received
    where $introspection$ data.series::http_event_collector_token host=$selected_host$ 
    by _time data.token_name data.format data.transport $span_min_60s$

          </query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="tcp_in_hostname_base">
    <query>$metrics$ TERM(group=tcpin_connections) NOT(DispatchManager) TERM(hostname=$selected_host$) earliest=$selection_earliest_tcp_out$ latest=$selection_latest_tcp_out$ 
| fillnull ingest_pipe value=0 
| table _time host ingest_pipe kb tcp_Bps tcp_KBps tcp_avg_thruput tcp_Kprocessed tcp_eps process_time_ms chan_new_kBps evt_misc_kBps evt_raw_kBps evt_fields_kBps evt_fn_kBps evt_fv_kBps evt_fn_str_kBps evt_fn_meta_dyn_kBps evt_fn_meta_predef_kBps evt_fn_meta_str_kBps evt_fv_num_kBps evt_fv_str_kBps evt_fv_predef_kBps evt_fv_offlen_kBps evt_fv_fp_kBps build version os arch hostname guid fwdType ssl lastIndexer ack connectionType sourceHost sourceIp sourcePort destPort


</query>
    <earliest>$selection_earliest_tcp_out$</earliest>
    <latest>$selection_latest_tcp_out$</latest>
  </search>
  <search base="tcp_in_hostname_base" id="tcp_in_hostname">
    <query>
| stats 
    $tcp_in_hostname_aggregator$(kb) as kb
    $tcp_in_hostname_aggregator$(tcp_Bps) as tcp_Bps
    $tcp_in_hostname_aggregator$(tcp_KBps) as tcp_KBps
    $tcp_in_hostname_aggregator$(tcp_avg_thruput) as tcp_avg_thruput
    $tcp_in_hostname_aggregator$(tcp_Kprocessed) as tcp_Kprocessed
    $tcp_in_hostname_aggregator$(tcp_eps) as tcp_eps
    $tcp_in_hostname_aggregator$(process_time_ms) as process_time_ms
    $tcp_in_hostname_aggregator$(chan_new_kBps) as chan_new_kBps
    $tcp_in_hostname_aggregator$(evt_misc_kBps) as evt_misc_kBps
    $tcp_in_hostname_aggregator$(evt_raw_kBps) as evt_raw_kBps
    $tcp_in_hostname_aggregator$(evt_fields_kBps) as evt_fields_kBps
    $tcp_in_hostname_aggregator$(evt_fn_kBps) as evt_fn_kBps
    $tcp_in_hostname_aggregator$(evt_fv_kBps) as evt_fv_kBps
    $tcp_in_hostname_aggregator$(evt_fn_str_kBps) as evt_fn_str_kBps
    $tcp_in_hostname_aggregator$(evt_fn_meta_dyn_kBps) as evt_fn_meta_dyn_kBps
    $tcp_in_hostname_aggregator$(evt_fn_meta_predef_kBps) as evt_fn_meta_predef_kBps
    $tcp_in_hostname_aggregator$(evt_fn_meta_str_kBps) as evt_fn_meta_str_kBps
    $tcp_in_hostname_aggregator$(evt_fv_num_kBps) as evt_fv_num_kBps
    $tcp_in_hostname_aggregator$(evt_fv_str_kBps) as evt_fv_str_kBps
    $tcp_in_hostname_aggregator$(evt_fv_predef_kBps) as evt_fv_predef_kBps
    $tcp_in_hostname_aggregator$(evt_fv_offlen_kBps) as evt_fv_offlen_kBps
    $tcp_in_hostname_aggregator$(evt_fv_fp_kBps) as evt_fv_fp_kBps
    values(build) as _build 
    values(version) as _version
    values(os) as _os 
    values(arch) as _arch 
    values(guid) as _guid 
    values(fwdType) as _fwdType 
    values(ssl) as _ssl 
    values(ack) as _ack 
    values(connectionType) as _connectionType 
    values(sourcePort) as _sourcePort 
    values(sourceHost) as _sourceHost
    values(sourceIp) as _sourceIp
    values(destPort) as _destPort by host ingest_pipe
| table *
</query>
    <progress>
      <eval token="tcp_incoming.build">mvjoin($result._build$,",")</eval>
      <eval token="tcp_incoming.version">mvjoin($result._version$,",")</eval>
      <eval token="tcp_incoming.os">mvjoin($result._os$,",")</eval>
      <eval token="tcp_incoming.arch">mvjoin($result._arch$,",")</eval>
      <eval token="tcp_incoming.hostname">mvjoin($result._hostname$,",")</eval>
      <eval token="tcp_incoming.guid">mvjoin($result._guid$,",")</eval>
      <eval token="tcp_incoming.fwdType">mvjoin($result._fwdType$,",")</eval>
      <eval token="tcp_incoming.ssl">mvjoin($result._ssl$,",")</eval>
      <eval token="tcp_incoming.ack">mvjoin($result._ack$,",")</eval>
      <eval token="tcp_incoming.connectionType">mvjoin($result._connectionType$,",")</eval>
      <eval token="tcp_incoming.sourceHost">mvjoin($result._sourceHost$,",")</eval>
      <eval token="tcp_incoming.sourceIp">mvjoin($result._sourceIp$,",")</eval>
      <eval token="tcp_incoming.destPort">mvjoin($result._destPort$,",")</eval>
      <eval token="tcp_incoming.sourcePort">mvjoin($result._sourcePort$,",")</eval>
      <eval token="multiple_host_warning">if(mvcount($result._guid$)&gt;1,"show",NULL)</eval>
    </progress>
  </search>
  <search id="per_regex_series_thruput_filtered" base="per_regex_series_thruput">
    <done>
      <set token="finished_regex_per_series_thruput">| noop</set>
    </done>
    <query>| search group=$selected_regex_group$ ingest_pipe=$filter_pipelines$ 
| bin _time $span_min_30s$ 
| stats $selected_regex_per_series_function$(cpu) as cpu
    $selected_regex_per_series_function$(cpupe) as cpupe
    $selected_regex_per_series_function$(bytes) as bytes
    $selected_regex_per_series_function$(ev) as ev
    by _time series host</query>
  </search>
  <search base="tcp_in_hostname">
    <query>| stats values(host) as hosts
| eval hosts="host IN (".mvjoin(hosts,", ").")"</query>
    <done>
      <set token="targets_drill_up">$result.hosts$</set>
    </done>
    <progress>
      <set token="targets_drill_up">$result.hosts$</set>
    </progress>
  </search>
  <search base="introspection_resource_usage_host">
    <query>
| stats
values(_swap) as _swap
values(_os_name) as _os_name
values(_os_name_ext) as _os_name_ext
values(_os_version) as _os_version
values(_mem) as _mem
values(_cpu_count) as _cpu_count
values(_cpu_arch) as _cpu_arch
values(_virtual_cpu_count) as _virtual_cpu_count
values(_splunk_version) as _splunk_version
values(_os_build) as _os_build
values(_instance_guid) as _instance_guid      
      
    </query>
    <progress>
      <eval token="host.os_name">mvjoin($result._os_name$,",")</eval>
      <eval token="host.swap">mvjoin($result._swap$,",")</eval>
      <eval token="host.cpu_count">mvjoin($result._cpu_count$,",")</eval>
      <eval token="host.cpu_arch">mvjoin($result._cpu_arch$,",")</eval>
      <eval token="host.mem">mvjoin($result._mem$,",")</eval>
      <eval token="host.virtual_cpu_count">mvjoin($result._virtual_cpu_count$,",")</eval>
      <eval token="host.splunk_version">mvjoin($result._splunk_version$,",")</eval>
      <eval token="host.build">mvjoin($result._os_build$,",")</eval>
      <eval token="host.instance_guid">mvjoin($result._instance_guid$,",")</eval>
      <eval token="host.os_version">mvjoin($result._os_version$,",")</eval>
      <eval token="host.os_name_ext">mvjoin($result._os_name_ext$,",")</eval>
      <eval token="host.hostwide_introspection_sid">$job.sid$</eval>
      <eval token="multiple_host_warning">if(mvcount($result._instance_guid$)&gt;1,"show",NULL)</eval>
    </progress>
    <done>
      <set token="host.os_name">$result._os_name$</set>
      <set token="host.swap">$result._swap$</set>
      <set token="host.cpu_count">$result._cpu_count$</set>
      <set token="host.cpu_arch">$result._cpu_arch$</set>
      <set token="host.mem">$result._mem$</set>
      <set token="host.virtual_cpu_count">$result._virtual_cpu_count$</set>
      <set token="host.splunk_version">$result._splunk_version$</set>
      <set token="host.build">$result._os_build$</set>
      <set token="host.instance_guid">$result._instance_guid$</set>
      <set token="host.os_version">$result._os_version$</set>
      <set token="host.os_name_ext">$result._os_name_ext$</set>
      <set token="host.hostwide_introspection_sid"></set>
      <eval token="multiple_host_warning">if(mvcount($result._instance_guid$)&gt;1,"show",NULL)</eval>
    </done>
  </search>
  <search id="introspection_resource_usage_host">
    <query>| tstats
        $selected_introspection_function_host$(data.cpu_system_pct) as host_cpu_system_pct
        $selected_introspection_function_host$(data.cpu_user_pct) as host_cpu_user_pct
        $selected_introspection_function_host$(data.mem_used) as host_mem_used
        $selected_introspection_function_host$(data.normalized_load_avg_1min) as host_normalized_load_avg_1min
        $selected_introspection_function_host$(data.swap_used) as host_swap_used
        where component=hostwide $introspection$ host=$selected_host$ 
        by data.swap data.os_name data.os_name_ext data.os_version data.mem data.cpu_count data.cpu_arch data.virtual_cpu_count data.splunk_version data.os_build data.instance_guid host _time span=1sec 
        | rename data.* as _*
        </query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="introspection_resource_usage_per_process">
    <query>| tstats 
        $selected_introspection_function_per_process$(data.elapsed) as splunkd_elapsed
        $selected_introspection_function_per_process$(data.fd_used) as splunkd_fd_used
        $selected_introspection_function_per_process$(data.mem_used) as splunkd_mem_used
        $selected_introspection_function_per_process$(data.normalized_pct_cpu) as splunkd_normalized_pct_cpu
        $selected_introspection_function_per_process$(data.pct_cpu) as splunkd_pct_cpu
        $selected_introspection_function_per_process$(data.pct_memory) as splunkd_pct_memory
        $selected_introspection_function_per_process$(data.t_count) as splunkd_t_count
        $selected_introspection_function_per_process$(data.written_mb) as splunkd_written_mb
        $selected_introspection_function_per_process$(data.read_mb) as splunkd_read_mb
        where $introspection$ component::perprocess host=$selected_host$ data.process=splunkd
        by host data.process_type _time span=1s </query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="tcp_output_annotation">
    <query>| union 
    [ search $splunkd$ host=$selected_host$ TERM(statusee=TcpOutputProcessor) TERM(eventType=connect_fail) CASE(StatusMgr) 
    | eval annotation_label=destHost,
        annotation_category="connect fail"
        $show_tcp_out_panel$ 
    | table _time host anno*
        ] 
    [ search (index=_internal OR index=core_splunk_internal) sourcetype=splunkd host=$selected_host$ CASE(Tcpout) CASE(Processor) CASE(TCP) output processor has paused data flow 
    | rex field=_raw "Forwarding to output group (?&lt;group&gt;[^\s]+) has been blocked for (?&lt;duration&gt;\d+) seconds" 
    | eval annotation_label="Output group ".group." is delayed for ".duration."secs",
        annotation_category="TCP output processor has paused data flow" 
    | table _time host anno*]</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="annotation_channel_creation">
    <query>| union 
    [ search $splunkd$ host=$selected_host$ CASE(TailingProcessor) CASE(Pausing) CASE(TailReader) module 
    | eval annotation_label="Paused",
        annotation_category="TailingProcessor" 
    | table _time ann* ] 
    [ search $splunkd$ host=$selected_host$ TcpInputProc Error encountered for connection Broken pipe from TERM(src=*) sourcetype=splunkd 
    | eval annotation_label=src,
        annotation_category="Dropped forwarder" 
    | table _time ann*]</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="metrics_generation">
    <query>| tstats 
    min(_indextime) as min_index_time 
    max(_indextime) as max_index_time 
    count as event_count where $metrics$ sourcetype=splunkd host=$selected_host$ 
    TERM(name=thruput) (TERM(group=thruput) NOT(TERM(ingest_pipe*)) OR TERM(ingest_pipe=0)) by _time source $span_min_1s$ 
| eval min_delay=min_index_time-_time 
| eval max_delay=max_index_time-_time-$form.span_min_1s$
| streamstats count as count
| eventstats max(count) as max_count
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="thruput">
    <query>$metrics$ host=$selected_host$ TERM(group=thruput) TERM(name=*) NOT TERM(kb=0) NOT(name=idxsummary)
| fillnull ingest_pipe 0 
| bin _time $span_min_30s$
| stats
    $selected_thruput_function$(instantaneous_kbps) as instantaneous_kbps
    $selected_thruput_function$(instantaneous_eps) as instantaneous_eps
    $selected_thruput_function$(average_kbps) as average_kbps
    $selected_thruput_function$(total_k_processed) as total_k_processed
    $selected_thruput_function$(kb) as kb
    $selected_thruput_function$(ev) as ev
    $selected_thruput_function$(load_average) as load_average
    by _time ingest_pipe name</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="queue">
    <query>$metrics$ host=$selected_host$ TERM(group=queue) TERM(name=*) (NOT TERM(largest_size=0) TERM(max_size_kb=*) NOT(TERM(current_size_kb=0)))
| fillnull ingest_pipe 0 
| fillnull blocked false
| bin _time $span_min_30s$ 
| stats 
    avg(current_size_kb) as current_size_kb
    by _time ingest_pipe host name max_size_kb blocked
| eval normalized_pct=(current_size_kb/max_size_kb) * 100
| rename blocked as _blocked</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search base="queue" id="annotation_blocking">
    <query>| where _blocked="true" 
| eval 
    annotation_label= "pipeline #".ingest_pipe." blocked", 
    annotation_category=mvjoin(name,"+") 
| table _time anno* ingest_pipe 
| append 
    [ search $splunkd$ host=$selected_host$ sourcetype=splunkd CASE(IndexWriter) TERM(splunk-optimize) paused 
    | rex field=_raw "Too many tsidx files in idx=(?&lt;idx&gt;[^\s]+)" 
    | eval annotation_label="Too many tsidx ".idx, annotation_category="indexing paused" 
    | table _time anno*
    | eval ingest_pipe="*"
    ]</query>
  </search>
  <search id="event_delay_2">
    <query>| tstats count max(_indextime) as index_time where $splunkd$ host=$selected_host$ source=*splunkd.log* by source _time span=1s
| eval delay=index_time-_time </query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="tcpout_buffer">
    <query>$splunkd$ (sourcetype=metrics OR sourcetype=splunkd) Metrics host=$selected_host$ TERM(group=queue) TERM(name=*) (TERM(max_size=*) TERM(current_size=*) TERM(largest_size=*) TERM(smallest_size=*)) 
| fillnull ingest_pipe 0 
| eval normalized_pct=round((current_size/max_size) * 100,2) 
| eval blocked=if(normalized_pct&gt;99.8,"true","false") 
| table _time host name ingest_pipe blocked max_size normalized_pct current_size largest_size smallest_size
</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <search id="tcpout_buffer_filtered" base="tcpout_buffer">
    <query>
      | search ingest_pipe=$filter_pipelines$
    </query>
  </search>
  <search base="tcpout_buffer_filtered" id="tcpout_buffer_filtered_annotation">
    <query>| where blocked="true" 
| eval annotation_label="ingestion pipe ".ingest_pipe." is blocked",
    annotation_category=name
| table _time anno*</query>
  </search>
  <search id="annotation_cannot_send_data">
    <query>| tstats count where $splunkd$ host=$selected_host$ Could not send data to output queue by _time span=1s
| eval annotation_label="Could not send data to output queue"
| table _time anno*</query>
    <earliest>$time.earliest$</earliest>
    <latest>$time.latest$</latest>
  </search>
  <fieldset submitButton="false">
    <input type="time" token="time">
      <label>Select forwarder</label>
      <default>
        <earliest>-60m@m</earliest>
        <latest>now</latest>
      </default>
      <change>
        <condition match="isnotnull($time.latest$)">
          <eval token="form.duration_seconds">ceiling(relative_time(now(), $time.latest$)-relative_time(now(), $time.earliest$))</eval>
          <eval token="form.span_min_1s">floor($form.duration_seconds$/$selected_resolution$)</eval>
          <eval token="form.span_min_10s">if($form.span_min_1s$&lt;10,10,$form.span_min_1s$)</eval>
          <eval token="form.span_min_30s">if($form.span_min_1s$&lt;31,31,$form.span_min_1s$)</eval>
          <eval token="form.span_min_60s">if($form.span_min_1s$&lt;60,60,$form.span_min_1s$)</eval>
          <unset token="finished_per_series_thruput"></unset>
          <set token="series_thruput_max">0</set>
          <eval token="series_thruput_min">now()</eval>
        </condition>
      </change>
    </input>
    <input type="text" token="selected_host">
      <label>Enter host name</label>
      <change>
        <set token="filter_pipelines">*</set>
        <unset token="show_tcp_out_panel"></unset>
        <unset token="show_hostwide_panel"></unset>
        <unset token="show_queue_panel"></unset>
        <unset token="host.os_name">$result._os_name$</unset>
        <unset token="host.swap">$result._swap$</unset>
        <unset token="host.cpu_count">$result._cpu_count$</unset>
        <unset token="host.cpu_arch">$result._cpu_arch$</unset>
        <unset token="host.mem">$result._mem$</unset>
        <unset token="host.virtual_cpu_count">$result._virtual_cpu_count$</unset>
        <unset token="host.splunk_version">$result._splunk_version$</unset>
        <unset token="host.build">$result._os_build$</unset>
        <unset token="host.instance_guid">$result._instance_guid$</unset>
        <unset token="host.os_version">$result._os_version$</unset>
        <unset token="host.os_name_ext">$result._os_name_ext$</unset>
        <unset token="host.hostwide_introspection_sid"></unset>
        <unset token="tcp_incoming.build">$result._build$</unset>
        <unset token="tcp_incoming.version">$result._version$</unset>
        <unset token="tcp_incoming.os">$result._os$</unset>
        <unset token="tcp_incoming.arch">$result._arch$</unset>
        <unset token="tcp_incoming.hostname">$result._hostname$</unset>
        <unset token="tcp_incoming.guid">$result._guid$</unset>
        <unset token="tcp_incoming.fwdType">$result._fwdType$</unset>
        <unset token="tcp_incoming.ssl">$result._ssl$</unset>
        <unset token="tcp_incoming.ack">$result._ack$</unset>
        <unset token="tcp_incoming.connectionType">$result._connectionType$</unset>
        <unset token="tcp_incoming.sourceHost">$result._sourceHost$</unset>
        <unset token="tcp_incoming.sourceIp">$result._sourceIp$</unset>
        <unset token="tcp_incoming.destPort">$result._destPort$</unset>
        <unset token="tcp_incoming.sourcePort">$result._sourcePort$</unset>
      </change>
    </input>
    <input type="dropdown" token="filter_pipelines">
      <label>Filter to pipeline</label>
      <choice value="*">*</choice>
      <default>*</default>
      <fieldForLabel>ingest_pipe</fieldForLabel>
      <fieldForValue>ingest_pipe</fieldForValue>
      <search base="thruput">
        <query>
          | stats count by ingest_pipe
        </query>
      </search>
    </input>
    <input type="dropdown" token="selected_resolution">
      <label>Select number of bins</label>
      <choice value="100">100</choice>
      <choice value="250">250</choice>
      <choice value="500">500</choice>
      <choice value="750">750</choice>
      <choice value="1000">1000</choice>
      <initialValue>500</initialValue>
      <change>
        <eval token="form.duration_seconds">ceiling(relative_time(now(), $time.latest$)-relative_time(now(), $time.earliest$))</eval>
        <eval token="form.span_min_1s">floor($form.duration_seconds$/$selected_resolution$)</eval>
        <eval token="form.span_min_10s">if($form.span_min_1s$&lt;10,10,$form.span_min_1s$)</eval>
        <eval token="form.span_min_30s">if($form.span_min_1s$&lt;31,31,$form.span_min_1s$)</eval>
        <eval token="form.span_min_60s">if($form.span_min_1s$&lt;60,60,$form.span_min_1s$)</eval>
      </change>
    </input>
    <input type="text" token="span_min_60s" depends="$hide$">
      <label>span_min_60s</label>
      <prefix>span=</prefix>
      <suffix>sec</suffix>
      <initialValue>60</initialValue>
    </input>
    <input type="text" token="span_min_30s" depends="$hide$">
      <label>span_min_30s</label>
      <prefix>span=</prefix>
      <suffix>sec</suffix>
      <initialValue>30</initialValue>
    </input>
    <input type="text" token="span_min_10s" depends="$hide$">
      <label>span_min_10s</label>
      <prefix>span=</prefix>
      <suffix>sec</suffix>
      <initialValue>10</initialValue>
    </input>
    <input type="text" token="span_min_1s" depends="$hide$">
      <label>span_min_1s</label>
      <prefix>span=</prefix>
      <suffix>sec</suffix>
      <initialValue>1</initialValue>
    </input>
    <input type="text" token="duration_seconds" depends="$hide$">
      <label>duration_seconds</label>
    </input>
  </fieldset>
  <row depends="$hide_me$">
    <panel>
      <table>
        <search id="annotation_restarts">
          <query>host=$selected_host$ $splunkd$ source=*splunkd.log* 
    (CASE(ServerConfig) CASE(My) CASE(GUID))
    OR (CASE(IndexerService) CASE(Number) of threads CASE(IndexInitExecutor))
    OR (component=CMSlave CASE(CMSlave) TERM(event=addPeer) (TERM(Batch=1/*) OR (TERM(status=success) TERM(addType=*))))
    OR (CASE(IndexProcessor) CASE(initClustering) CASE(Registering) with the cluster TERM(master...)) 
    OR (loader CASE(Splunkd) starting build) 
    OR (CASE(ShutdownHandler) complete seconds) 
    OR (CASE(CMSlave) master sends new restart TERM(timeout=*) TERM(threshold=*)) OR (CASE(CMSlave) indexing ready loop TERM(status=success))
    OR (CASE(CMSlave) TERM(event=SummaryRegistration) Summaries have been registered completely on slave) 
    OR 
    (CASE(PipelineComponent) CASE(CallbackRunnerThread) is unusually busy) 
| rex field=_raw "IndexInitExecutor is set to (?&lt;indexInitExecutor_threads&gt;\d+)?" 
| rex field=_raw "Batch=1/(?&lt;num_batches&gt;\d+)" 
| rex field=_raw "Splunkd starting \(build (?&lt;build_id&gt;[0-9a-f]+)\)" 
| rex field=_raw "GUID is (?&lt;guid&gt;[0-9A-F\-]+)" 
| rex field=_raw "ShutdownHandler - Shutdown complete in (?&lt;shutdown_time&gt;\d+(?:\.\d+)?) seconds"     
| rex field=_raw "CMSlave - master sends new restart timeout=(?&lt;timeout&gt;\d+) threshold=(?&lt;threshold&gt;\d+(?:\.\d+)?)" 
| rex field=_raw " CallbackRunnerThread is unusually busy,  this may cause service delays: (?&lt;callbackrunner_error&gt;[^{]+)"
| eval annotation_label=case(
    searchmatch("SummaryRegistration"),"Summaries registered",
    searchmatch("indexing ready loop"),"Indexing ready",
    searchmatch("starting build"),"Started build ".build_id,
    searchmatch("initClustering"),"Joining cluster",
    isnotnull(callbackrunner_error),"CallbackRunnerThread delayed ".callbackrunner_error,
    isnotnull(threshold),"Restart requested",
    isnotnull(shutdown_time),"shutdown complete in ".shutdown_time."secs",
    isnotnull(guid),if(searchmatch("newly"),"New host with","Restarted host with ").guid,
    isnotnull(num_batches),"Adding ".num_batches." batches",
    isnotnull(executor_threads),"indexInitExecutor_threads".indexInitExecutor_threads,
    isnotnull(status),"Batch adding finished ".addType." in ".total_time_ms."ms"
    ), annotation_category=component
| table _time ann* _raw</query>
          <earliest>$time.earliest$</earliest>
          <latest>$time.latest$</latest>
          <sampleRatio>1</sampleRatio>
        </search>
        <option name="refresh.display">progressbar</option>
      </table>
    </panel>
  </row>
  <row rejects="$selected_host$">
    <panel>
      <title></title>
      <html>
        <h1 style="text-align:center">Please enter an exact hostname</h1>
      </html>
    </panel>
  </row>
  <row depends="$multiple_host_warning$">
    <panel>
      <html>
        <h1 style="text-align:center;color:red">WARNING MULTIPLE GUIDS DETECTED FOR SINGLE HOSTNAME - DASHBOARD RESULTS CANNOT BE TRUSTED</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel depends="$show_hostwide_panel$">
      <html>
    <style>
			
			
#info_table {
  font-family: "Trebuchet MS", Arial, Helvetica, sans-serif;
  border-collapse: collapse;
  width: 100%;
}

#info_table td, #info_table th {
  border: 1px solid #ddd;
  padding: 8px;
}

#info_table tr:nth-child(even){background-color: #f2f2f2;}

#info_table tr:hover {background-color: #ddd;}

#info_table th {
  padding-top: 12px;
  padding-bottom: 12px;
  text-align: left;
  background-color: #4CAF50;
  color: white;
}
			</style> 
        <h2>Hostwide introspection reports</h2>
        <table id="info_table">
          <tr>
            <th>Attribute</th>
            <th>Value</th>
          </tr>
        <tr>
          <td>Splunk Version</td>
			    <td>$host.splunk_version$</td>
		    </tr>
        <tr>
          <td>Build</td>
			    <td>$host.build$</td>
		    </tr>
        <tr>
          <td>CPU architecture</td>
			    <td>$host.cpu_arch$</td>
		    </tr>
        <tr>
          <td>Real cores</td>
			    <td>$host.cpu_count$</td>
		    </tr>
        <tr>
          <td>Memory</td>
			    <td>$host.mem$</td>
		    </tr>
        <tr>
          <td>Swap</td>
			    <td>$host.swap$</td>
		    </tr>
        <tr>
          <td>Virtual cores</td>
			    <td>$host.virtual_cpu_count$</td>
		    </tr>
        <tr>
          <td>GUID</td>
			    <td>$host.instance_guid$</td>
	      </tr>
        <tr>
          <td>Operating System</td>
    			<td>$host.os_name$</td>
		    </tr>
        <tr>
          <td>Operating System Extended</td>
    			<td>$host.os_name_ext$</td>
		    </tr>
        <tr>
          <td>Operating System</td>
    			<td>$host.os_version$</td>
		    </tr>
      </table>
    </html>
    </panel>
    <panel depends="$show_tcp_out_panel$">
      <html>
        <h2>Upstream host reports</h2>
        <table id="info_table">
          <tr>
            <th>Attribute</th>
            <th>Value</th>
          </tr>
        <tr>
          <td>Splunk version</td>
			    <td>$tcp_incoming.version$</td>
		    </tr>
        <tr>
          <td>Build</td>
			    <td>$tcp_incoming.build$</td>
		    </tr>
        <tr>
          <td>CPU architecture</td>
			    <td>$tcp_incoming.arch$</td>
		    </tr>
        <tr>
          <td>Forwarder type</td>
			    <td>$tcp_incoming.fwdType$</td>
		    </tr>
        <tr>
          <td>ACK</td>
			    <td>$tcp_incoming.ack$</td>
	      </tr>
        <tr>
          <td>SSL configured</td>
			    <td>$tcp_incoming.ssl$</td>
		    </tr>
        <tr>
          <td>GUID</td>
			    <td>$tcp_incoming.guid$</td>
	      </tr>
        <tr>
          <td>Connection type</td>
    			<td>$tcp_incoming.connectionType$</td>
		    </tr>
        <tr>
          <td>Source host</td>
    			<td>$tcp_incoming.sourceHost$</td>
		    </tr>
        <tr>
          <td>Source IP</td>
    			<td>$tcp_incoming.sourceIp$</td>
		    </tr>
        <tr>
          <td>Source Port</td>
    			<td>$tcp_incoming.sourcePort$</td>
		    </tr>
        <tr>
          <td>Destination Port</td>
    			<td>$tcp_incoming.destPort$</td>
		    </tr>
      </table>
</html>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>The throughput per pipeline for $selected_host$ for all pipelines with restart annotation (click to select pipeline)</title>
      <input type="dropdown" token="selected_thruput">
        <label>Select thruput metric</label>
        <choice value="thruput">thruput</choice>
        <fieldForLabel>name</fieldForLabel>
        <fieldForValue>name</fieldForValue>
        <search base="thruput">
          <query>| stats count by name
| where name != "thruput"</query>
        </search>
        <default>thruput</default>
      </input>
      <input type="dropdown" token="selected_thruput_variable">
        <label>Select field to show</label>
        <choice value="instantaneous_kbps">instantaneous_kbps</choice>
        <choice value="instantaneous_eps">instantaneous_eps</choice>
        <choice value="average_kbps">average_kbps</choice>
        <choice value="total_k_processed">total_k_processed</choice>
        <choice value="kb">kb</choice>
        <choice value="ev">ev</choice>
        <default>instantaneous_kbps</default>
      </input>
      <input type="dropdown" token="selected_thruput_function">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <search base="annotation_restarts" type="annotation"></search>
        <search base="thruput">
          <query>| search name=$selected_thruput$ 
| timechart $span_min_30s$ limit=0 
    avg($selected_thruput_variable$) by ingest_pipe 
| eval *=0 
| foreach * 
    [| eval &lt;&lt;FIELD&gt;&gt;=round('&lt;&lt;FIELD&gt;&gt;',2),
    *='*'+if(isnotnull('&lt;&lt;FIELD&gt;&gt;'),'&lt;&lt;FIELD&gt;&gt;',0)]</query>
        </search>
        <selection>
          <set token="selection_thruput_earliest">$start$</set>
          <set token="selection_thruput_latest">$end$</set>
        </selection>
        <option name="charting.axisY2.enabled">1</option>
        <option name="charting.chart">column</option>
        <option name="charting.chart.overlayFields">*</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">all</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">461</option>
        <option name="refresh.display">progressbar</option>
        <drilldown>
          <set token="form.filter_pipelines">$click.name2$</set>
        </drilldown>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Create sharable link</title>
      <html>
        <h2 style="text-align:center">
        <a target="_blank" rel="noopener noreferrer" href="debug_ingestion?form.time.earliest=$selection_thruput_earliest$&amp;form.time.latest=$selection_thruput_latest$&amp;form.selected_host=$selected_host$&amp;form.span_min_30s=$form.span_min_30s$&amp;form.span_min_10s=$form.span_min_10s$&amp;form.selected_resolution=$selected_resolution$">Open this dashboard in a new window with absolute for selected range time</a>
        </h2>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$" rejects="$show_hec_panel$">
    <panel>
      <title>HEC details per token - not pipeline aware</title>
      <html>
        <h1 style="text-align:center">No HEC ingestion detected</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$,$show_hec_panel$">
    <panel>
      <title>HEC details per token - not pipeline aware</title>
      <input type="multiselect" token="selected_hec_fields">
        <label>Select attribute</label>
        <choice value="avg(num_of_events)">num_of_events</choice>
        <choice value="avg(num_of_parser_errors)">num_of_parser_errors</choice>
        <choice value="avg(num_of_requests)">num_of_requests</choice>
        <choice value="avg(num_of_requests_in_mint_format)">num_of_requests_in_mint_format</choice>
        <choice value="avg(num_of_requests_to_disabled_token)">num_of_requests_to_disabled_token</choice>
        <choice value="avg(total_bytes_indexed)">total_bytes_indexed</choice>
        <choice value="avg(total_bytes_received)">total_bytes_received</choice>
        <delimiter> </delimiter>
        <default>avg(total_bytes_indexed),avg(total_bytes_received),avg(num_of_events),avg(num_of_parser_errors)</default>
      </input>
      <input type="dropdown" token="hec_split_by">
        <label>Split HEC data by</label>
        <choice value="by data.format">format</choice>
        <choice value="by data.token_name">token_name</choice>
        <choice value="by data.transport">transport</choice>
        <choice value="| noop">no split</choice>
        <default>| noop</default>
      </input>
      <input type="dropdown" token="selected_hec_token">
        <label>Select HEC token</label>
        <choice value="*">*</choice>
        <fieldForLabel>data.token_name</fieldForLabel>
        <fieldForValue>data.token_name</fieldForValue>
        <search base="hec_token_base">
          <query>| stats count by data.token_name </query>
          <progress>
            <eval token="show_hec_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </progress>
          <done>
            <eval token="show_hec_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
        </search>
        <default>*</default>
      </input>
      <chart>
        <title>Select window and indexer to drill in</title>
        <search base="annotation" type="annotation"></search>
        <search base="hec_token_base">
          <query>| search data.token_name=$selected_hec_token$
| timechart limit=50 $span_min_10s$ $selected_hec_fields$ $hec_split_by$</query>
        </search>
        <option name="charting.axisY.scale">log</option>
        <option name="charting.chart">line</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">377</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$" rejects="$show_hostwide_panel$">
    <panel>
      <title>Hostwide resource usage with annotated restarts</title>
      <html>
        <h1 style="text-align:center">No introspection data found</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$,$show_hostwide_panel$">
    <panel>
      <title>Hostwide resource usage with annotated restarts</title>
      <input type="dropdown" token="host_attributes">
        <label>Show metrics</label>
        <choice value="| table _time total_mem mem_used normalized_load_avg_1min">memory</choice>
        <choice value="| table _time max_cpu  host_cpu_system_pct+host_cpu_user_pct cpu_system_pct cpu_user_pct normalized_load_avg_1min">cpu</choice>
        <choice value="| table _time total_swap swap_used normalized_load_avg_1min">swap</choice>
        <default>| table _time max_cpu  host_cpu_system_pct+host_cpu_user_pct cpu_system_pct cpu_user_pct normalized_load_avg_1min</default>
      </input>
      <input type="dropdown" token="selected_introspection_function_host">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <search base="introspection_resource_usage_host">
          <progress>
            <eval token="show_hostwide_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </progress>
          <done>
            <eval token="show_hostwide_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
          <query>| rename _mem as total_mem 
| rename _swap as total_swap 
| eval total_cpu=host_cpu_system_pct+host_cpu_user_pct

| timechart $span_min_10s$
    $selected_introspection_function_host$(total_cpu) as "host_cpu_system_pct+host_cpu_user_pct"
    $selected_introspection_function_host$(host_cpu_system_pct) as cpu_system_pct 
    $selected_introspection_function_host$(host_cpu_user_pct) as cpu_user_pct 
    $selected_introspection_function_host$(host_normalized_load_avg_1min) as normalized_load_avg_1min
    $selected_introspection_function_host$(host_swap_used) as swap_used 
    $selected_introspection_function_host$(host_mem_used) as mem_used 
    max(total_swap) as total_swap
    max(total_mem) as total_mem
| eval max_cpu=100
    $host_attributes$</query>
        </search>
        <search base="annotation_restarts" type="annotation"></search>
        <option name="charting.axisY2.abbreviation">auto</option>
        <option name="charting.axisY2.enabled">1</option>
        <option name="charting.chart">line</option>
        <option name="charting.chart.overlayFields">normalized_load_avg_1min</option>
        <option name="charting.chart.stackMode">default</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">394</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
    <panel>
      <title>Splunkd resource usage with with annotated restarts</title>
      <input type="dropdown" token="per_process_attributes">
        <label>Show metrics</label>
        <choice value="| table _time *normalized_pct_cpu*">CPU %</choice>
        <choice value="| table _time *cpu* | fields - *normalized_pct_cpu*">CPU</choice>
        <choice value="| table _time *_mem* | fields - *pct*">Memory</choice>
        <choice value="| table _time *fd_used*">File handles</choice>
        <choice value="| table _time *_mb*">Data</choice>
        <default>| table _time *normalized_pct_cpu*</default>
      </input>
      <input type="dropdown" token="selected_introspection_function_per_process">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>sum</default>
      </input>
      <input type="dropdown" token="per_process_split_by">
        <label>Split by</label>
        <choice value="| noop">None</choice>
        <choice value="by data.process_type">Process type</choice>
        <default>| noop</default>
      </input>
      <chart>
        <title>Utilization of Splunk server</title>
        <search base="introspection_resource_usage_per_process">
          <query>| timechart $span_min_10s$
    $selected_introspection_function_per_process$(splunkd_elapsed) as splunkd_elapsed
    $selected_introspection_function_per_process$(splunkd_fd_used) as splunkd_fd_used
    $selected_introspection_function_per_process$(splunkd_mem_used) as splunkd_mem_used
    $selected_introspection_function_per_process$(splunkd_normalized_pct_cpu) as splunkd_normalized_pct_cpu
    $selected_introspection_function_per_process$(splunkd_pct_cpu) as splunkd_pct_cpu
    $selected_introspection_function_per_process$(splunkd_pct_memory) as splunkd_pct_memory
    $selected_introspection_function_per_process$(splunkd_t_count) as splunkd_t_count
    $selected_introspection_function_per_process$(splunkd_written_mb) as splunkd_written_mb
    $selected_introspection_function_per_process$(splunkd_read_mb) as splunkd_read_mb
    $per_process_split_by$
$per_process_attributes$</query>
        </search>
        <search base="annotation_restarts" type="annotation"></search>
        <option name="charting.chart">line</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">394</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$" rejects="$show_queue_panel$">
    <panel>
      <title>Queue filling for pipeline $filter_pipelines$ on $selected_host$</title>
      <html>
        <h1 style="text-align:center">No queuing detected !!!</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$,$show_queue_panel$">
    <panel>
      <title>Queue filling for pipeline $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="queue_fill">
        <label>Queue fill measure</label>
        <choice value="normalized_pct">Normalized %</choice>
        <choice value="current_size_kb">Absolute</choice>
        <default>current_size_kb</default>
      </input>
      <chart>
        <search base="annotation_blocking_filtered" type="annotation">
          <query>| noop</query>
        </search>
        <search base="queue">
          <query>| search ingest_pipe=$filter_pipelines$ 
| timechart $span_min_30s$ avg($queue_fill$) by name</query>
          <progress>
            <eval token="show_queue_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </progress>
          <done>
            <eval token="show_queue_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
        </search>
        <option name="charting.chart">column</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">353</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Throughput for $selected_group$ on $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="selected_group">
        <label>Select series</label>
        <choice value="index">per_index_thruput</choice>
        <choice value="host">per_host_thruput</choice>
        <choice value="source">per_source_thruput</choice>
        <choice value="sourcetype">per_sourcetype_thruput</choice>
        <default>sourcetype</default>
      </input>
      <input type="dropdown" token="selected_per_series_variable">
        <label>Select field to show</label>
        <choice value="kb">kb</choice>
        <choice value="eps">eps</choice>
        <choice value="ev">ev</choice>
        <choice value="kbps">kbps</choice>
        <choice value="max_age">max_age</choice>
        <choice value="avg_age">avg_age</choice>
        <default>eps</default>
      </input>
      <input type="dropdown" token="selected_per_series_function">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <title>Select range to reveal what forwarders where connecting to what pipelines for the duration</title>
        <search base="annotation_parsing_problems" type="annotation">
          <query>
            
| eval annotation_label=naughty_$selected_group$,
    annotation_category=reason
| table _time anno*


          </query>
        </search>
        <search base="per_series_thruput_filtered">
          <done>
            <set token="finished_per_series_thruput">| noop</set>
          </done>
          <query>| timechart $span_min_30s$ limit=30 $selected_per_series_function$($selected_per_series_variable$) as $selected_per_series_variable$ by series
| foreach * 
    [| eval &lt;&lt;FIELD&gt;&gt;=round('&lt;&lt;FIELD&gt;&gt;',2)]</query>
        </search>
        <selection>
          <eval token="series_thruput_max">if($end$&gt;$series_thruput_max$,$end$,$series_thruput_max$)</eval>
          <eval token="series_thruput_min">if($start$&lt;$series_thruput_min$,$start$,$series_thruput_min$)</eval>
          <eval token="selection_per_series_earliest">if(isnotnull($finished_per_series_thruput$) AND $start$!=$series_thruput_min$, $start$, NULL)</eval>
          <eval token="selection_per_series_latest">if(isnotnull($finished_per_series_thruput$) AND $end$ != $series_thruput_max$, $end$, NULL)</eval>
        </selection>
        <option name="charting.chart">column</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">419</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$,$finished_per_series_thruput$,$selection_per_series_earliest$,$selection_per_series_latest$" rejects="$show_forwarders_panel$">
    <panel>
      <title>Forwarders connecting to ...</title>
      <html>
        <h1 style="text-align:center">No incoming forwarders detected</h1>
      </html>
    </panel>
  </row>
  <row depends="$finished_per_series_thruput$,$selection_per_series_earliest$,$selection_per_series_latest$,$show_forwarders_panel$">
    <panel>
      <title>Forwarders connecting to $selected_host$ showing $selected_host_count$ forwarders</title>
      <input type="dropdown" token="selected_host_version">
        <label>Filter forwarder version</label>
        <choice value="*">*</choice>
        <search base="connecting_forwarders">
          <query>| stats count by version
| eval label=version." (".count." instances)"</query>
        </search>
        <fieldForLabel>label</fieldForLabel>
        <fieldForValue>version</fieldForValue>
        <default>*</default>
      </input>
      <input type="dropdown" token="selected_host_type">
        <label>Filter forwarder type</label>
        <choice value="*">*</choice>
        <search base="connecting_forwarders">
          <query>| stats count by type
| eval label=type." (".count." instances)"
| sort - count</query>
        </search>
        <fieldForLabel>label</fieldForLabel>
        <fieldForValue>type</fieldForValue>
        <default>*</default>
      </input>
      <input type="dropdown" token="selected_host_os">
        <label>Filter forwarder OS</label>
        <choice value="*">*</choice>
        <search base="connecting_forwarders">
          <query>| stats count by os
| eval label=os." (".count." instances)"
| sort - count</query>
        </search>
        <fieldForLabel>label</fieldForLabel>
        <fieldForValue>os</fieldForValue>
        <default>*</default>
      </input>
      <table>
        <title>For more detail click on some forwarders and more charts will open allowing you to compare performance and behaviours of those you selected</title>
        <search base="connecting_forwarders">
          <progress>
            <set token="selected_host_count">$job.resultCount$</set>
          </progress>
          <done>
            <set token="selected_host_count">$job.resultCount$</set>
            <eval token="show_forwarders_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
          <query>| search type=$selected_host_type$ os=$selected_host_os$ version=$selected_host_version$ ingest_pipe=$filter_pipelines$
| rename guid_count as "# guids"
| eval "connected for"=mentions."/".readings, "connected %"=(mentions/readings)* 100
| table hostname sourceHost sourcePort guid guid_count ingest_pipe "volume ranking" "speed ranking" "indexer coverage"  "%" "connected for" "connected %" "max speed" "speed variability" "data" "data %" "os" "type" "version" arch 
| sort 0 - "data"
| rename ingest_pipe as "ingest pipe"</query>
        </search>
        <option name="count">20</option>
        <option name="drilldown">cell</option>
        <option name="refresh.display">progressbar</option>
        <format type="number" field="indexer coverage">
          <option name="precision">0</option>
          <option name="unit">%</option>
        </format>
        <format type="number" field="max speed">
          <option name="precision">0</option>
          <option name="unit">KBps</option>
        </format>
        <format type="number" field="speed variability">
          <option name="precision">0</option>
          <option name="unit">%</option>
        </format>
        <format type="color" field="%">
          <colorPalette type="list">[#D93F3C,#FFFFFF]</colorPalette>
          <scale type="threshold">99</scale>
        </format>
        <format type="color" field="max speed">
          <colorPalette type="minMidMax" maxColor="#31A35F" minColor="#FFFFFF"></colorPalette>
          <scale type="minMidMax"></scale>
        </format>
        <format type="color" field="speed variability">
          <colorPalette type="minMidMax" maxColor="#1E93C6" minColor="#FFFFFF"></colorPalette>
          <scale type="minMidMax"></scale>
        </format>
        <format type="number" field="data">
          <option name="unit">GB</option>
        </format>
        <format type="color" field="data">
          <colorPalette type="minMidMax" maxColor="#31A35F" minColor="#FFFFFF"></colorPalette>
          <scale type="minMidMax"></scale>
        </format>
        <format type="number" field="data %">
          <option name="precision">0</option>
          <option name="unit">%</option>
        </format>
        <format type="color" field="data %">
          <colorPalette type="minMidMax" maxColor="#31A35F" minColor="#FFFFFF"></colorPalette>
          <scale type="minMidMax"></scale>
        </format>
        <format type="number" field="%">
          <option name="precision">0</option>
        </format>
        <format type="number" field="connected %">
          <option name="precision">0</option>
          <option name="unit">%</option>
        </format>
        <format type="color" field="connected %">
          <colorPalette type="list">[#FFFFFF,#D93F3C]</colorPalette>
          <scale type="threshold">80</scale>
        </format>
        <drilldown>
          <link target="_blank">debug_ingestion?form.selected_host=$row.hostname$&amp;form.time.earliest=$time.earliest$&amp;form.time.latest=$time.latest$&amp;form.span_min_30s=$form.span_min_30s$&amp;form.span_min_10s=$form.span_min_10s$&amp;form.selected_resolution=$selected_resolution$</link>
        </drilldown>
      </table>
    </panel>
  </row>
  <row depends="$selected_host$,$finished_per_series_thruput$,$selection_per_series_earliest$,$selection_per_series_latest$" rejects="$show_parsing_panel$">
    <panel>
      <title>Parsing problems ...</title>
      <html>
        <h1 style="text-align:center">No parsing issues detected in selected time range</h1>
      </html>
    </panel>
  </row>
  <row depends="$finished_per_series_thruput$,$selection_per_series_earliest$,$selection_per_series_latest$,$show_parsing_panel$">
    <panel>
      <title>Parsing problems $selected_host$ for all pipelines</title>
      <table>
        <search base="annotation_parsing_problems">
          <done>
            <eval token="show_parsing_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
          <query>| search _time&gt;$selection_per_series_earliest$ _time&lt;$selection_per_series_latest$
| stats count values(reason) as reason by naughty_host naughty_sourcetype naughty_source
| sort - count
| eval _url="index=* host=\"".naughty_host."\" sourcetype=\"".naughty_sourcetype."\" source::\"".naughty_source."\" _index_earliest=$selection_per_series_earliest$ _index_latest=$selection_per_series_latest$ earliest=$time.earliest$ latest=$time.latest$"</query>
        </search>
        <option name="count">10</option>
        <option name="refresh.display">progressbar</option>
        <drilldown>
          <link target="_blank">search?earliest=$time.earliest$&amp;latest=$time.latest$&amp;q=$row._url$</link>
        </drilldown>
      </table>
    </panel>
  </row>
  <row depends="$selected_host$" rejects="$show_regex_panel$">
    <panel>
      <title>Regex performance ...</title>
      <html>
        <h1 style="text-align:center">Please set regex_cpu_profiling = TRUE in limits.conf to enable the logging for this panel</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$,$show_regex_panel$">
    <panel>
      <title>Regex performance for $selected_group$ on $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="selected_regex_group">
        <label>Select series</label>
        <choice value="per_index_regex_cpu">index</choice>
        <choice value="per_host_regex_cpu">host</choice>
        <choice value="per_source_regex_cpu">source</choice>
        <choice value="per_sourcetype_regex_cpu">sourcetype</choice>
        <default>per_sourcetype_regex_cpu</default>
      </input>
      <input type="dropdown" token="selected_regex_per_series_variable">
        <label>Select field to show</label>
        <choice value="cpu">cpu</choice>
        <choice value="cpupe">cpupe</choice>
        <choice value="ev">ev</choice>
        <choice value="bytes">bytes</choice>
        <default>cpu</default>
      </input>
      <input type="dropdown" token="selected_regex_per_series_function">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <search base="per_regex_series_thruput_filtered">
          <done>
            <set token="finished_regex_per_series_thruput">| noop</set>
          </done>
          <query>| timechart $span_min_30s$ limit=30 $selected_regex_per_series_function$($selected_regex_per_series_variable$) as $selected_regex_per_series_variable$ by series
| foreach * 
    [| eval &lt;&lt;FIELD&gt;&gt;=round('&lt;&lt;FIELD&gt;&gt;',2)]</query>
        </search>
        <option name="charting.chart">column</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">419</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Pipeline processor cpu and execution for pipeline $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="selected_processor_function">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <input type="dropdown" token="selected_processor">
        <label>Select process and name</label>
        <choice value="processor=* name=*">processor=* name=*</choice>
        <default>processor=* name=*</default>
        <fieldForLabel>search</fieldForLabel>
        <fieldForValue>search</fieldForValue>
        <search base="pipeline_processor_aggregated">
          <query>| stats count by processor name 
| eval search="processor=".processor." name=".name 
| appendpipe 
    [| stats count by name 
    | eval search="name=".name." processor=*"]

| appendpipe 
    [| stats count by processor 
    | eval search="name=* processor=".processor]</query>
        </search>
      </input>
      <input type="dropdown" token="selected_processor_variable">
        <label>Select variable to plot</label>
        <choice value="cpu_seconds">cpu_seconds</choice>
        <choice value="executes">executes</choice>
        <choice value="cumulative_hits">cumulative_hits</choice>
        <default>cpu_seconds</default>
      </input>
      <chart>
        <search base="pipeline_processor_aggregated">
          <query>| search ingest_pipe=$filter_pipelines$ $selected_processor$ 
| eval key="#".ingest_pipe." ".processor." &amp; ".name 
| timechart limit=50 $span_min_30s$ avg($selected_processor_variable$) by key</query>
        </search>
        <search base="annotation_parsing_problems" type="annotation">| eval annotation_label=naughty_$selected_group$,
    annotation_category=reason
| table _time anno*</search>
        <option name="charting.chart">line</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">484</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Channel creation for pipeline $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="channel_variable">
        <label>Select channel metric</label>
        <choice value="current_size*">current_size</choice>
        <choice value="inactive_channels*">inactive_channels</choice>
        <choice value="new_channels*">new_channels</choice>
        <choice value="removed_channels*">removed_channels</choice>
        <choice value="reclaimed_channels*">reclaimed_channels</choice>
        <choice value="timedout_channels*">timedout_channels</choice>
        <choice value="abandoned_channels*">abandoned_channels</choice>
        <choice value="*">*</choice>
        <default>*</default>
      </input>
      <input type="dropdown" token="selected_channels_function">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <search base="annotation_channel_creation" type="annotation">
          <query>

          </query>
        </search>
        <search base="channels_filtered">
          <query>
          
| fields _time $channel_variable$</query>
        </search>
        <option name="charting.chart">column</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">467</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$" rejects="$show_tcp_out_panel$">
    <panel>
      <title>TCP output metrics for pipeline $filter_pipelines$ on $selected_host$</title>
      <html>
        <h1 style="text-align:center">No TCP out on $selected_host$, host is most likely to be an indexer</h1>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$,$show_tcp_out_panel$">
    <panel>
      <title>TCP output metrics for pipeline $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="tcp_out_variable">
        <label>Select variable</label>
        <choice value="tcp_Kprocessed">tcp_Kprocessed</choice>
        <choice value="tcp_avg_thruput">tcp_avg_thruput</choice>
        <choice value="tcp_eps">tcp_eps</choice>
        <choice value="kb">kb</choice>
        <default>tcp_avg_thruput</default>
      </input>
      <input type="dropdown" token="tcp_out_splitby">
        <label>Select variable</label>
        <choice value="destIp">destIp</choice>
        <choice value="name">name</choice>
        <choice value="channel">channel</choice>
        <choice value="group">group</choice>
        <default>destIp</default>
      </input>
      <input type="dropdown" token="tcp_out_overlay">
        <label>Overlay</label>
        <choice value="count dc(destIp)">count + discount count</choice>
        <choice value="dc(destIp)">distinct count</choice>
        <choice value="count">count</choice>
        <default>dc(destIp)</default>
      </input>
      <chart>
        <title>Select time range to see what targets recieved data from this host</title>
        <search base="tcp_output_annotation" type="annotation">
          <query>
 
    </query>
        </search>
        <search base="tcp_out">
          <progress>
            <eval token="show_tcp_out_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </progress>
          <done>
            <eval token="show_tcp_out_panel">if($job.resultCount$=0,NULL,"| noop")</eval>
          </done>
          <query>| eval data="drop" 
| search ingest_pipe=$filter_pipelines$ 
| rex field=name "^(?&lt;group&gt;[^:]+):[^:]+:[^:]+:(?&lt;channel&gt;\d+)" 
| appendpipe 
    [| timechart $span_min_30s$ limit=80 avg($tcp_out_variable$) by $tcp_out_splitby$] 
| appendpipe 
    [| sort 0 + _time 
    | streamstats $tcp_out_overlay$ ] 
| where isnull(data) 
| stats values(*) as * by _time</query>
        </search>
        <selection>
          <eval token="selection_earliest_tcp_out">$start$</eval>
          <eval token="selection_latest_tcp_out">$end$</eval>
        </selection>
        <option name="charting.axisY2.enabled">1</option>
        <option name="charting.chart">column</option>
        <option name="charting.chart.overlayFields">count,dc(destIp)</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="charting.legend.placement">top</option>
        <option name="height">412</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$,$selection_earliest_tcp_out$,$selection_latest_tcp_out$">
    <panel>
      <title>TCP output buffer for pipeline $filter_pipelines$ on $selected_host$</title>
      <input type="dropdown" token="tcp_out_buff_attribute">
        <label>Show buffer metric</label>
        <choice value="largest_size">largest_size</choice>
        <choice value="current_size">current_size</choice>
        <choice value="normalized_pct">normalized_pct</choice>
        <choice value="smallest_size">smallest_size</choice>
        <default>largest_size</default>
      </input>
      <input type="dropdown" token="tcp_out_buff_aggregate">
        <label>Show buffer aggregate</label>
        <choice value="avg">avg</choice>
        <choice value="max">max</choice>
        <choice value="p95">p95</choice>
        <choice value="min">min</choice>
        <default>p95</default>
      </input>
      <chart>
        <search base="tcpout_buffer_filtered">
          <query>| eval label=name."-".ingest_pipe
| timechart $span_min_10s$ $tcp_out_buff_aggregate$($tcp_out_buff_attribute$) by label</query>
        </search>
        <search base="tcpout_buffer_filtered_annotation" type="annotation">
          <query>
| noop
		  </query>
        </search>
        <option name="charting.chart">line</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$,$selection_earliest_tcp_out$,$selection_latest_tcp_out$">
    <panel>
      <title>Targets recieving data from $selected_host$ for selected duration - drill up to recieving target</title>
      <input type="dropdown" token="tcp_in_hostname_attribute">
        <label>Select attribute</label>
        <choice value="kb">kb</choice>
        <choice value="tcp_Bps">tcp_Bps</choice>
        <choice value="tcp_KBps">tcp_KBps</choice>
        <choice value="tcp_avg_thruput">tcp_avg_thruput</choice>
        <choice value="tcp_Kprocessed">tcp_Kprocessed</choice>
        <choice value="tcp_eps">tcp_eps</choice>
        <choice value="process_time_ms">process_time_ms</choice>
        <choice value="chan_new_kBps">chan_new_kBps</choice>
        <choice value="evt_misc_kBps">evt_misc_kBps</choice>
        <choice value="evt_raw_kBps">evt_raw_kBps</choice>
        <choice value="evt_fields_kBps">evt_fields_kBps</choice>
        <choice value="evt_fn_kBps">evt_fn_kBps</choice>
        <choice value="evt_fv_kBps">evt_fv_kBps</choice>
        <choice value="evt_fn_str_kBps">evt_fn_str_kBps</choice>
        <choice value="evt_fn_meta_dyn_kBps">evt_fn_meta_dyn_kBps</choice>
        <choice value="evt_fn_meta_predef_kBps">evt_fn_meta_predef_kBps</choice>
        <choice value="evt_fn_meta_str_kBps">evt_fn_meta_str_kBps</choice>
        <choice value="evt_fv_num_kBps">evt_fv_num_kBps</choice>
        <choice value="evt_fv_str_kBps">evt_fv_str_kBps</choice>
        <choice value="evt_fv_predef_kBps">evt_fv_predef_kBps</choice>
        <choice value="evt_fv_offlen_kBps">evt_fv_offlen_kBps</choice>
        <choice value="evt_fv_fp_kBps">evt_fv_fp_kBps</choice>
        <default>kb</default>
      </input>
      <input type="dropdown" token="tcp_in_hostname_aggregator">
        <label>Select aggregation function</label>
        <choice value="avg">average</choice>
        <choice value="median">median</choice>
        <choice value="mean">mean</choice>
        <choice value="stdev">standard dev</choice>
        <choice value="per_second">per_second</choice>
        <choice value="p90">p90</choice>
        <choice value="p95">p95</choice>
        <choice value="p99">p99</choice>
        <choice value="max">max</choice>
        <choice value="min">min</choice>
        <choice value="sum">sum</choice>
        <choice value="range">range</choice>
        <choice value="var">variance</choice>
        <default>avg</default>
      </input>
      <chart>
        <search base="tcp_in_hostname">
          <query>| xyseries host ingest_pipe $tcp_in_hostname_attribute$ 
| foreach * 
       [| eval &lt;&lt;FIELD&gt;&gt;=if(isnum(&lt;&lt;FIELD&gt;&gt;),round('&lt;&lt;FIELD&gt;&gt;',2),host)]</query>
        </search>
        <option name="charting.chart">column</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">all</option>
        <option name="charting.legend.placement">none</option>
        <option name="height">423</option>
        <option name="refresh.display">progressbar</option>
        <drilldown>
          <link target="_blank">debug_ingestion?form.selected_host=$click.value$&amp;form.time.earliest=$selection_earliest_tcp_out$&amp;form.time.latest=$selection_latest_tcp_out$&amp;form.filter_pipelines=$click.name2$&amp;form.span_min_30s=$form.span_min_30s$&amp;form.span_min_10s=$form.span_min_10s$&amp;form.selected_resolution=$selected_resolution$</link>
        </drilldown>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$,$selection_earliest_tcp_out$,$selection_latest_tcp_out$,$targets_drill_up$">
    <panel>
      <title>Drill up to view the ingestion for the targets recieving data from this host</title>
      <html>
        <h2 style="text-align:center">
        <a target="_blank" rel="noopener noreferrer" href="debug_incoming_forwarders?form.time.earliest=$time.earliest$&amp;form.time.latest=$time.latest$&amp;form.selected_targets=$targets_drill_up$">Debug ingestion for  upstream targets</a>
        </h2>
      </html>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Frequency of metrics execution</title>
      <input type="dropdown" token="delay_metric">
        <label>Show delay metric</label>
        <choice value="| where count != 1 AND count != max_count | table _time max_delay min_delay">Event delay</choice>
        <choice value="| xyseries _time source event_count">Execution frequency</choice>
        <default>| xyseries _time source event_count</default>
      </input>
      <chart>
        <title>Multiple files, gaps and dips are all bad</title>
        <search base="metrics_generation">
          <query>$delay_metric$</query>
        </search>
        <selection>
          <set token="event_delay_min">$start$</set>
          <set token="event_delay_max">$end$</set>
        </selection>
        <option name="charting.chart">column</option>
        <option name="charting.chart.overlayFields">expected_readings</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">none</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
  <row depends="$selected_host$">
    <panel>
      <title>Delay of splunkd.log</title>
      <input type="dropdown" token="delay_metric_2">
        <label>Show delay metric</label>
        <choice value="sum(count)">count</choice>
        <choice value="avg(delay) as delay">avg(delay)</choice>
        <choice value="p95(delay) as delay">p95(delay)</choice>
        <choice value="max(delay) as delay">max(delay)</choice>
        <default>avg(delay) as delay</default>
      </input>
      <chart>
        <title>Multiple files and delay is a sign of excessive logging or a throughput (congestion) issue</title>
        <search base="event_delay_2">
          <query>| timechart $span_min_1s$ $delay_metric_2$ by source</query>
        </search>
        <search base="annotation_cannot_send_data" type="annotation"></search>
        <option name="charting.chart">line</option>
        <option name="charting.chart.stackMode">stacked</option>
        <option name="charting.drilldown">all</option>
        <option name="refresh.display">progressbar</option>
      </chart>
    </panel>
  </row>
</form>
